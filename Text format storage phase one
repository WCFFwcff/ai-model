import transformers
import speech_recognition as sr
import pyttsx3
import webbrowser
import datetime

def load_text_responses(filename):
    """Loads responses from a text file.

    Args:
        filename (str): The name of the text file containing pre-defined responses.

    Returns:
        list: A list of pre-defined responses loaded from the text file.
    """

    with open(filename, 'r') as f:
        return [line.strip() for line in f.readlines()]

def save_conversation(prompt, response, filename="conversation.txt", mode="a"):
    """Saves the user prompt and chatbot response to a text file.

    Args:
        prompt (str): The user's input prompt.
        response (str): The chatbot's generated response.
        filename (str, optional): The name of the text file to save the conversation. Defaults to "conversation.txt".
        mode (str, optional): The mode for opening the file. Defaults to "a" (append).
    """

    with open(filename, mode) as f:
        f.write(f"User: {prompt}\nChatbot: {response}\n\n")

def get_greeting(current_time):
    """Returns a personalized greeting based on the time of day.

    Args:
        current_time (datetime.datetime): The current time as a datetime object.

    Returns:
        str: A greeting appropriate for the time of day.
    """

    if current_time.hour < 12:
        return "Good morning!"
    elif current_time.hour < 17:
        return "Good afternoon!"
    else:
        return "Good evening!"

def generate_response_and_greet(prompt):
    """Generates a response using a greeting and leverages the pre-trained model.

    Args:
        prompt (str): The user's input prompt or query.

    Returns:
        str: The final response with greeting and the model-generated text.
    """

    current_time = datetime.datetime.now()
    greeting = get_greeting(current_time)

    # (Replace with appropriate model names/paths)
    tokenizer = transformers.AutoTokenizer.from_pretrained("gpt2")
    model = transformers.AutoModelWithLMHead.from_pretrained("gpt2")

    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(**inputs, max_length=50)
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    response = greeting + " " + generated_text
    save_conversation(prompt, response)  # Save conversation to file

    return response

def listen_and_respond():
    """Listens for user input, generates a response, and speaks it using TTS."""

    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        audio = recognizer.listen(source)

    try:
        user_input = recognizer.recognize_google(audio)
        print("You said: " + user_input)
        response = generate_response_and_greet(user_input)
        print("I said: " + response)

        engine = pyttsx3.init()
        engine.say(response)
        engine.runAndWait()

        if "open" in user_input.lower() and ("google" in user_input.lower() or "youtube" in user_input.lower()):
            if "google" in user_input.lower():
                website = "https://www.google.com"
            else:
                website = "https://www.youtube.com"
            webbrowser.open(website, new=2)  # Open website in a new tab

    except sr.UnknownValueError:
        print("Sorry, I could not understand audio")
    except sr.RequestError as e:
        print("Request failed; {0}".format(e))

if __name__ == "__main__":
    while True:
        user_choice = input("Enter 't' for text input or 'v' for voice input (or 'q' to quit): ")
        if user_choice == 't':
            prompt = input("Your prompt: ")
            response = generate_response_and

#txt method one
